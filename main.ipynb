{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Desafio Técnico - Analista de Inteligência Artificial\n",
    "# Análise de Vídeo, Classificação de Objetos e Processamento de Áudio"
   ],
   "id": "c24da4c49e99df0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Este notebook implementa uma solução completa para análise de cena gravada em vídeo"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importação das Libs",
   "id": "5c4be89cd90f2a4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- #### Separação do vídeo e Aúdio",
   "id": "279437b90928a1b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- #### Extração de frames e armazenamento em banco",
   "id": "83f65c987e7a5fbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# arquivos\n",
    "import os\n",
    "\n",
    "# Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# Imagens\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from moviepy import VideoFileClip\n",
    "\n",
    "# Plotagem\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Utilitarios\n",
    "import json"
   ],
   "id": "cab68e78f80297d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "caminho_arquivo_mp4 = \"data/loveletter_bananagrams_caneca.mp4\"\n",
    "\n",
    "video_saida = \"data/video_sem_audio.mp4\"\n",
    "audio_saida = \"data/audio.mp3\""
   ],
   "id": "d2788eec7d255074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(caminho_arquivo_mp4):\n",
    "  print(\"Arquivo não encontrado\")"
   ],
   "id": "b2a58c5d0ac2692",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "video = VideoFileClip(caminho_arquivo_mp4)",
   "id": "2e28c4bb61478b1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Separação do vídeo sem o aúdio",
   "id": "548c2146c375dfb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "video_sem_audio = video.without_audio()\n",
    "video_sem_audio.write_videofile(video_saida, logger=None)"
   ],
   "id": "ded2d01d65fe4d9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Separação do aúdio",
   "id": "d4771a11b08e1ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio = video.audio\n",
    "audio.write_audiofile(audio_saida, logger=None)"
   ],
   "id": "3f4333a5784c21ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fechamento dos recursos",
   "id": "1401438b4154dbff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "video.close()\n",
    "audio.close()\n",
    "video_sem_audio.close()"
   ],
   "id": "249cde34c778528b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2.  Armazenamento e Tratamento de Imagens",
   "id": "11cf6029095098f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Extração de frames",
   "id": "bb1929607d6eaeb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Criação de banco de dados SQLITE local",
   "id": "72eefdf58898708e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_folder = \"data/db_sqlite\"  # Pasta\n",
    "db_file = \"frames.db\"          # Arquivo do banco\n",
    "db_path = os.path.join(db_folder, db_file)"
   ],
   "id": "60801c9340f4e95e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Criando tabela",
   "id": "6f8be4ee757491a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS video_frames\n",
    "                (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    video_name TEXT NOT NULL,\n",
    "                    frame_number INTEGER NOT NULL,\n",
    "                    timestamp REAL,\n",
    "                    frame_data BLOB NOT NULL,\n",
    "                    width INTEGER,\n",
    "                    height INTEGER,\n",
    "                    channels INTEGER DEFAULT 3,\n",
    "                    color_space TEXT DEFAULT 'BGR',\n",
    "                    mean_r REAL,\n",
    "                    mean_g REAL,\n",
    "                    mean_b REAL,\n",
    "                    std_r REAL,\n",
    "                    std_g REAL,\n",
    "                    std_b REAL,\n",
    "                    compression_type TEXT DEFAULT 'pickle',\n",
    "                    custom_metadata TEXT,\n",
    "                    scene_type TEXT,\n",
    "                    motion_level TEXT,\n",
    "                    lighting_condition TEXT,\n",
    "                    notes TEXT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    UNIQUE (frame_number)\n",
    "                    )\n",
    "                    ''')\n",
    "conn.close()"
   ],
   "id": "b028fd49ca62fe57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Criando indices",
   "id": "b46a3443819c6944"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "            CREATE INDEX IF NOT EXISTS idx_video_name ON video_frames(video_name)\n",
    "        ''')\n",
    "\n",
    "cursor.execute('''\n",
    "            CREATE INDEX IF NOT EXISTS idx_frame_number ON video_frames(frame_number)\n",
    "        ''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ],
   "id": "f789578657bbd697",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Funções auxiliares",
   "id": "ae33294aaba38685"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_color_statistics(frame):\n",
    "    \"\"\"Calcula estatísticas de cor do frame\"\"\"\n",
    "    if len(frame.shape) == 3:\n",
    "        b, g, r = cv2.split(frame)\n",
    "        stats = {\n",
    "            'mean_r': float(np.mean(r)),\n",
    "            'mean_g': float(np.mean(g)),\n",
    "            'mean_b': float(np.mean(b)),\n",
    "            'std_r': float(np.std(r)),\n",
    "            'std_g': float(np.std(g)),\n",
    "            'std_b': float(np.std(b))\n",
    "        }\n",
    "    else:\n",
    "        # Frame em escala de cinza\n",
    "        mean_val = float(np.mean(frame))\n",
    "        std_val = float(np.std(frame))\n",
    "        stats = {\n",
    "            'mean_r': mean_val,\n",
    "            'mean_g': mean_val,\n",
    "            'mean_b': mean_val,\n",
    "            'std_r': std_val,\n",
    "            'std_g': std_val,\n",
    "            'std_b': std_val\n",
    "        }\n",
    "    return stats"
   ],
   "id": "3d04c258c004fe74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_frame(video_name, frame_number, frame, timestamp=None, compression='pickle', metadata=None):\n",
    "    \"\"\"Salva um frame individual no banco de dados com análise de cor e metadados customizados\"\"\"\n",
    "    # Calcula estatísticas do frame\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    stats = calculate_color_statistics(frame)\n",
    "\n",
    "    # Processa metadados customizados\n",
    "    custom_metadata_json = None\n",
    "    scene_type = None\n",
    "    motion_level = None\n",
    "    lighting_condition = None\n",
    "    notes = None\n",
    "\n",
    "    if metadata:\n",
    "        # Se metadata for um dicionário, converte para JSON\n",
    "        if isinstance(metadata, dict):\n",
    "            custom_metadata_json = json.dumps(metadata)\n",
    "            # Extrai campos específicos se existirem\n",
    "            scene_type = metadata.get('scene_type')\n",
    "            motion_level = metadata.get('motion_level')\n",
    "            lighting_condition = metadata.get('lighting_condition')\n",
    "            notes = metadata.get('notes')\n",
    "        else:\n",
    "            # Se for string, usa como notes\n",
    "            notes = str(metadata)\n",
    "\n",
    "    # Converte o frame para bytes\n",
    "    if compression == 'pickle':\n",
    "        frame_bytes = pickle.dumps(frame)\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "    channels = frame.shape[2] if len(frame.shape) == 3 else 1\n",
    "    color_space = 'BGR' if channels == 3 else 'GRAY'\n",
    "\n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO video_frames\n",
    "        (video_name, frame_number, timestamp, frame_data, width, height,\n",
    "         channels, color_space, mean_r, mean_g, mean_b, std_r, std_g, std_b,\n",
    "         compression_type, custom_metadata, scene_type,\n",
    "         motion_level, lighting_condition, notes)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (video_name, frame_number, timestamp, frame_bytes, width, height,\n",
    "              channels, color_space, stats['mean_r'], stats['mean_g'], stats['mean_b'],\n",
    "              stats['std_r'], stats['std_g'], stats['std_b'], compression,\n",
    "              custom_metadata_json, scene_type, motion_level, lighting_condition,\n",
    "              notes))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ],
   "id": "8394cc422fd0c62c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_frame_content(frame, timestamp):\n",
    "    \"\"\"Exemplo de função para gerar metadados automaticamente\"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Análise simples de brilho\n",
    "    brightness = np.mean(frame)\n",
    "    if brightness < 80:\n",
    "        lighting = \"dark\"\n",
    "    elif brightness > 180:\n",
    "        lighting = \"bright\"\n",
    "    else:\n",
    "        lighting = \"normal\"\n",
    "\n",
    "    # Análise de movimento (baseada em variação de pixels)\n",
    "    frame_std = np.std(frame)\n",
    "    if frame_std < 20:\n",
    "        motion = \"static\"\n",
    "    elif frame_std < 50:\n",
    "        motion = \"low\"\n",
    "    else:\n",
    "        motion = \"high\"\n",
    "\n",
    "    # Análise de cena (baseada em canais de cor)\n",
    "    b, g, r = cv2.split(frame)\n",
    "    avg_b, avg_g, avg_r = np.mean(b), np.mean(g), np.mean(r)\n",
    "\n",
    "    if avg_g > avg_r and avg_g > avg_b:\n",
    "        scene = \"outdoor\"  # Muito verde pode indicar vegetação\n",
    "    elif avg_b > avg_r and avg_b > avg_g:\n",
    "        scene = \"sky\"  # Muito azul pode ser céu\n",
    "    else:\n",
    "        scene = \"indoor\"  # Caso geral\n",
    "\n",
    "    return {\n",
    "        'scene_type': scene,\n",
    "        'motion_level': motion,\n",
    "        'lighting_condition': lighting,\n",
    "        'brightness_value': float(brightness),\n",
    "        'frame_std': float(frame_std),\n",
    "        'resolution': f\"{width}x{height}\",\n",
    "        'notes': f\"Frame capturado em {timestamp:.1f}s\"\n",
    "    }"
   ],
   "id": "77a5760c1592cd6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_saida)\n",
    "\n",
    "if not cap.isOpened():\n",
    "  raise ValueError(f\"Erro ao abrir o vídeo: {video_saida}\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "time_interval = 0.1\n",
    "\n",
    "frame_interval = int(fps * time_interval)\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = total_frames / fps\n",
    "saved_count = 0\n",
    "sample_index = 0\n",
    "compression='pickle'"
   ],
   "id": "3c2d82815399aee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    current_time = sample_index * time_interval\n",
    "\n",
    "    if current_time >= duration:\n",
    "        break\n",
    "\n",
    "    target_frame = int(current_time * fps)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    metadata = analyze_frame_content(frame, current_time)\n",
    "\n",
    "    rounded_timestamp = round(current_time, 2)\n",
    "    save_frame('video_sem_audio', target_frame, frame, rounded_timestamp, compression, metadata)\n",
    "    saved_count += 1\n",
    "\n",
    "    if saved_count % 10 == 0:\n",
    "        progress = (current_time / duration) * 100\n",
    "        print(f\"Progresso: {progress:.1f}% - Tempo: {current_time:.1f}s - Frames salvos: {saved_count}\")\n",
    "\n",
    "    sample_index += 1\n",
    "\n",
    "cap.release()"
   ],
   "id": "b914618ad9c93074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Análise e Processamento de Imagens",
   "id": "5a6ea655720e263"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Funções auxiliares",
   "id": "1329d9dda3468930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_histogram(frame):\n",
    "    \"\"\"Calcula histograma da imagem\"\"\"\n",
    "    histograms = {}\n",
    "\n",
    "    if len(frame.shape) == 2:  # Imagem em escala de cinza\n",
    "        histograms['gray'] = cv2.calcHist([frame], [0], None, [256], [0, 256]).flatten()\n",
    "    else:  # Imagem colorida (BGR)\n",
    "        colors = ['blue', 'green', 'red']\n",
    "        for i, color in enumerate(colors):\n",
    "            histograms[color] = cv2.calcHist([frame], [i], None, [256], [0, 256]).flatten()\n",
    "\n",
    "    return histograms"
   ],
   "id": "4d616906e801cf52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_frame_from_db(frame_id):\n",
    "    \"\"\"Carrega um frame específico do banco de dados\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute('''\n",
    "        SELECT frame_data, compression_type FROM video_frames WHERE id = ?\n",
    "    ''', (frame_id,))\n",
    "\n",
    "    result = cursor.fetchone()\n",
    "    if not result:\n",
    "        return None\n",
    "\n",
    "    frame_bytes, compression = result\n",
    "    frame = pickle.loads(frame_bytes)\n",
    "\n",
    "    conn.close()\n",
    "    return frame"
   ],
   "id": "5b0e0640aea06de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_histogram(frame, title=\"Histograma\", save_path=None):\n",
    "    \"\"\"Plota o histograma de uma imagem\"\"\"\n",
    "    histograms = calculate_histogram(frame)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if 'gray' in histograms:\n",
    "        # Imagem em escala de cinza\n",
    "        plt.plot(histograms['gray'], color='black', alpha=0.7)\n",
    "        plt.title(f'{title} - Escala de Cinza')\n",
    "        plt.xlabel('Intensidade do Pixel')\n",
    "        plt.ylabel('Frequência')\n",
    "    else:\n",
    "        # Imagem colorida\n",
    "        colors = ['blue', 'green', 'red']\n",
    "        for color in colors:\n",
    "            plt.plot(histograms[color], color=color, alpha=0.7, label=color.capitalize())\n",
    "\n",
    "        plt.title(f'{title} - RGB')\n",
    "        plt.xlabel('Intensidade do Pixel')\n",
    "        plt.ylabel('Frequência')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.xlim([0, 256])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Histograma salvo em: {save_path}\")\n",
    "\n",
    "    plt.close()"
   ],
   "id": "90877b23e04a87a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def apply_clahe(self, frame, clip_limit=2.0, tile_grid_size=(8,8)):\n",
    "    \"\"\"Aplica CLAHE (Contrast Limited Adaptive Histogram Equalization)\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    if len(frame.shape) == 3:\n",
    "        # Imagem colorida - aplica CLAHE no canal Y (YUV)\n",
    "        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)\n",
    "        yuv[:,:,0] = clahe.apply(yuv[:,:,0])\n",
    "        result = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "    else:\n",
    "        # Imagem em escala de cinza\n",
    "        result = clahe.apply(frame)\n",
    "\n",
    "    return result"
   ],
   "id": "e7450609ed6fc8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def equalize_histogram(frame):\n",
    "    \"\"\"Aplica equalização de histograma na imagem\"\"\"\n",
    "    if len(frame.shape) == 3:\n",
    "        # Imagem colorida - converte para YUV, equaliza Y, converte de volta\n",
    "        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)\n",
    "        yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])\n",
    "        equalized = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "    else:\n",
    "        # Imagem em escala de cinza\n",
    "        equalized = cv2.equalizeHist(frame)\n",
    "\n",
    "    return equalized"
   ],
   "id": "4780b1b1517a53e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_histograms(frame_original, frame_equalized, title=\"Comparação\", save_path=None):\n",
    "    \"\"\"Compara histogramas antes e depois da equalização\"\"\"\n",
    "    hist_original = calculate_histogram(frame_original)\n",
    "    hist_equalized = calculate_histogram(frame_equalized)\n",
    "\n",
    "    if 'gray' in hist_original:\n",
    "        # Escala de cinza\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        ax1.plot(hist_original['gray'], color='black', alpha=0.7)\n",
    "        ax1.set_title('Histograma Original')\n",
    "        ax1.set_xlabel('Intensidade')\n",
    "        ax1.set_ylabel('Frequência')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        ax2.plot(hist_equalized['gray'], color='black', alpha=0.7)\n",
    "        ax2.set_title('Histograma Equalizado')\n",
    "        ax2.set_xlabel('Intensidade')\n",
    "        ax2.set_ylabel('Frequência')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        # Colorida\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        colors = ['blue', 'green', 'red']\n",
    "\n",
    "        for color in colors:\n",
    "            ax1.plot(hist_original[color], color=color, alpha=0.7, label=color.capitalize())\n",
    "            ax2.plot(hist_equalized[color], color=color, alpha=0.7, label=color.capitalize())\n",
    "\n",
    "        ax1.set_title('Histograma Original')\n",
    "        ax1.set_xlabel('Intensidade')\n",
    "        ax1.set_ylabel('Frequência')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        ax2.set_title('Histograma Equalizado')\n",
    "        ax2.set_xlabel('Intensidade')\n",
    "        ax2.set_ylabel('Frequência')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Comparação salva em: {save_path}\")\n",
    "\n",
    "    # IMPORTANTE: Fecha a figura para liberar memória\n",
    "    plt.close()"
   ],
   "id": "8c066e70e17c48ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_histogram_analysis = \"data/histogram_analysis\"\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(f'''\n",
    "                SELECT id, video_name, frame_number, timestamp, compression_type\n",
    "                FROM video_frames\n",
    "                ORDER BY frame_number\n",
    "            ''')\n",
    "\n",
    "frames_info = cursor.fetchall()\n",
    "conn.close()\n",
    "\n",
    "if not frames_info:\n",
    "    print(\"Nenhum frame encontrado no banco de dados!\")"
   ],
   "id": "4162272c2cca9c7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "use_clahe = False\n",
    "\n",
    "for i, (frame_id, vid_name, frame_num, timestamp, compression) in enumerate(frames_info):\n",
    "    print(f\"Processando frame {i+1}/{len(frames_info)} - ID: {frame_id} tipo_frame_id: {type(frame_id)}\")\n",
    "\n",
    "    # Carrega o frame\n",
    "    frame = load_frame_from_db(frame_id)\n",
    "    if frame is None:\n",
    "        print(f\"Erro ao carregar frame ID {frame_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Frame carregado - Tipo: {type(frame)}, Shape: {getattr(frame, 'shape', 'N/A')}\")\n",
    "\n",
    "\n",
    "    # Nomes dos arquivos\n",
    "    base_name = f\"{vid_name}_frame_{frame_num}_t{timestamp:.1f}s\"\n",
    "\n",
    "    # 1. Plota histograma original\n",
    "    hist_path = f\"{output_histogram_analysis}/{base_name}_histogram.png\"\n",
    "\n",
    "    plot_histogram(frame, f\"Frame {frame_num} - {timestamp:.1f}s\", hist_path)\n",
    "\n",
    "    # 2. Aplica equalização\n",
    "    if use_clahe:\n",
    "        equalized_frame = apply_clahe(frame)\n",
    "        eq_type = \"CLAHE\"\n",
    "    else:\n",
    "        equalized_frame = equalize_histogram(frame)\n",
    "        eq_type = \"Standard\"\n",
    "\n",
    "        # 3. Salva imagem original e equalizada\n",
    "        orig_path = f\"{output_histogram_analysis}/{base_name}_original.jpg\"\n",
    "        eq_path = f\"{output_histogram_analysis}/{base_name}_equalized_{eq_type.lower()}.jpg\"\n",
    "\n",
    "        cv2.imwrite(str(orig_path), frame)\n",
    "        cv2.imwrite(str(eq_path), equalized_frame)\n",
    "\n",
    "        # 4. Compara histogramas\n",
    "        comp_path = f\"{output_histogram_analysis}/{base_name}_comparison_{eq_type.lower()}.png\"\n",
    "        compare_histograms(frame, equalized_frame,\n",
    "                              f\"Frame {frame_num} - {eq_type} Equalization\", comp_path)\n",
    "\n",
    "print(f\"\\nProcessamento concluído! Resultados salvos em: {output_histogram_analysis}\")"
   ],
   "id": "58bf38bd8c339a69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classificação com Machine Learning MODELO NÃO SUPERVISIONADO DE CLUSTERS",
   "id": "7a1082a085153c1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Extração e visualização dos dados",
   "id": "68b21b2d5d19d3ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "query = f\"SELECT * FROM video_frames\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n"
   ],
   "id": "e21084878c77f36f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Shape dos dados: {df.shape}\")\n",
    "print(f\"Colunas: {df.columns.tolist()}\")\n",
    "print(f\"\\nTipos de dados:\\n{df.dtypes.value_counts()}\")\n",
    "print(f\"\\nValores nulos:\\n{df.isnull().sum().sum()}\")"
   ],
   "id": "d727053d596d252d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Extrair dados da coluna metadata_features",
   "id": "189b05f8d82e279f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metadata_features = []\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        metadata = json.loads(row['custom_metadata'])\n",
    "        metadata_features.append({\n",
    "            'brightness_value': metadata.get('brightness_value', 0),\n",
    "            'frame_std': metadata.get('frame_std', 0),\n",
    "            'motion_level_meta': metadata.get('motion_level', 'unknown')\n",
    "        })\n",
    "    except:\n",
    "        metadata_features.append({\n",
    "            'brightness_value': 0,\n",
    "            'frame_std': 0,\n",
    "            'motion_level_meta': 'unknown'\n",
    "        })"
   ],
   "id": "5309cf2ef3238c8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metadata_df = pd.DataFrame(metadata_features)\n",
    "df = pd.concat([df, metadata_df], axis=1)"
   ],
   "id": "f81c963bcdf013fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar features adicionais\n",
    "df['color_range'] = df['std_r'] + df['std_g'] + df['std_b']\n",
    "df['mean_brightness'] = (df['mean_r'] + df['mean_g'] + df['mean_b']) / 3\n",
    "df['color_variance'] = (df['std_r'] ** 2 + df['std_g'] ** 2 + df['std_b'] ** 2) / 3\n",
    "\n",
    "# Features de dominância de cor\n",
    "df['red_dominance'] = df['mean_r'] / (df['mean_r'] + df['mean_g'] + df['mean_b'] + 1e-6)\n",
    "df['green_dominance'] = df['mean_g'] / (df['mean_r'] + df['mean_g'] + df['mean_b'] + 1e-6)\n",
    "df['blue_dominance'] = df['mean_b'] / (df['mean_r'] + df['mean_g'] + df['mean_b'] + 1e-6)\n",
    "\n",
    "# Converter RGB para HSV aproximado\n",
    "df['max_rgb'] = df[['mean_r', 'mean_g', 'mean_b']].max(axis=1)\n",
    "df['min_rgb'] = df[['mean_r', 'mean_g', 'mean_b']].min(axis=1)\n",
    "df['chroma'] = df['max_rgb'] - df['min_rgb']\n",
    "\n",
    "# Saturação aproximada\n",
    "df['saturation'] = np.where(df['max_rgb'] > 0, df['chroma'] / df['max_rgb'], 0)\n",
    "\n",
    "# Matiz aproximada (simplificada)\n",
    "df['hue_component'] = np.where(df['chroma'] > 0,\n",
    "                               np.where(df['max_rgb'] == df['mean_r'],\n",
    "                                        (df['mean_g'] - df['mean_b']) / df['chroma'],\n",
    "                                        np.where(df['max_rgb'] == df['mean_g'],\n",
    "                                                 2 + (df['mean_b'] - df['mean_r']) / df['chroma'],\n",
    "                                                 4 + (df['mean_r'] - df['mean_g']) / df['chroma'])),\n",
    "                               0)"
   ],
   "id": "9d3f177cd68f74e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Preparar features para clustering\n",
   "id": "b7d2306987c31235"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Features para clustering\n",
    "feature_cols = [\n",
    "    # Média das cores\n",
    "    'mean_r', 'mean_g', 'mean_b',\n",
    "    # Desvios padrão (vermelho, verde e azul)\n",
    "    'std_r', 'std_g', 'std_b',\n",
    "    # Features derivadas\n",
    "    'brightness_value', 'frame_std',\n",
    "    'color_range', 'mean_brightness', 'color_variance',\n",
    "    'red_dominance', 'green_dominance', 'blue_dominance',\n",
    "    'saturation', 'hue_component'\n",
    "]"
   ],
   "id": "8374d501599a7dec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "for i, col in enumerate(feature_cols):\n",
    "    print(f\"  {i + 1}. {col}\")\n"
   ],
   "id": "1b0666b55eb2274c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Selecionando o X das features\n",
    "X = df[feature_cols].values\n",
    "\n",
    "# normalizar com StandartScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ],
   "id": "2f799e0113184448",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Analisar correlações\n",
   "id": "72359c7f2a18e652"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "corr_matrix = np.corrcoef(X_scaled.T)",
   "id": "bec6c3201c435003",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# mapa de calor\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix,\n",
    "            xticklabels=feature_cols,\n",
    "            yticklabels=feature_cols,\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            square=True,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlação entre Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b25322384269f8c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identificar features altamente correlacionadas\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(i + 1, len(corr_matrix)):\n",
    "        if abs(corr_matrix[i, j]) > 0.9:\n",
    "            high_corr_pairs.append((feature_cols[i], feature_cols[j], corr_matrix[i, j]))"
   ],
   "id": "23b98f4f1b598533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if high_corr_pairs:\n",
    "    print(\"\\nPares de features altamente correlacionadas (>0.9):\")\n",
    "    for f1, f2, corr in high_corr_pairs:\n",
    "        print(f\"  {f1} <-> {f2}: {corr:.3f}\")"
   ],
   "id": "f30afa06ed702b5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Determinar numero ótimo de clusters",
   "id": "4b94a42dd80a0c40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_k = 8\n",
    "K = range(2, min(max_k + 1, len(X_scaled) // 10))"
   ],
   "id": "56bce1ffe74dd039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inertias = []\n",
    "silhouettes = []\n",
    "calinskis = []\n",
    "davies = []\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_scaled, labels))\n",
    "    calinskis.append(calinski_harabasz_score(X_scaled, labels))\n",
    "    davies.append(davies_bouldin_score(X_scaled, labels))"
   ],
   "id": "2ea34234ab2ef556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plotar métricas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Elbow\n",
    "axes[0, 0].plot(K, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('Número de Clusters (k)')\n",
    "axes[0, 0].set_ylabel('Inércia')\n",
    "axes[0, 0].set_title('Método do Cotovelo')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette\n",
    "axes[0, 1].plot(K, silhouettes, 'go-', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Número de Clusters (k)')\n",
    "axes[0, 1].set_ylabel('Silhouette Score')\n",
    "axes[0, 1].set_title('Silhouette Score (↑ melhor)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Calinski-Harabasz\n",
    "axes[1, 0].plot(K, calinskis, 'ro-', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_xlabel('Número de Clusters (k)')\n",
    "axes[1, 0].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[1, 0].set_title('Calinski-Harabasz Score (↑ melhor)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Davies-Bouldin\n",
    "axes[1, 1].plot(K, davies, 'mo-', linewidth=2, markersize=8)\n",
    "axes[1, 1].set_xlabel('Número de Clusters (k)')\n",
    "axes[1, 1].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1, 1].set_title('Davies-Bouldin Score (↓ melhor)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "71b46ab1d526b54d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sugestão baseada em Cotovelo\n",
    "best_k = K[np.argmax(inertias)]\n",
    "print(f\"\\nSugestão baseada em Cotovelo Score: k = {best_k}\")\n",
    "\n",
    "# Sugestão baseada em Silhouette\n",
    "best_k = K[np.argmax(silhouettes)]\n",
    "print(f\"\\nSugestão baseada em Silhouette Score: k = {best_k}\")\n",
    "\n",
    "# Sugestão baseada em calinskis\n",
    "best_k = K[np.argmax(calinskis)]\n",
    "print(f\"\\nSugestão baseada em calinskis Score: k = {best_k}\")\n",
    "\n",
    "# Sugestão baseada em davies\n",
    "best_k = K[np.argmax(davies)]\n",
    "print(f\"\\nSugestão baseada em davies Score: k = {best_k}\")"
   ],
   "id": "71c4af101d125051",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Aplicando K-Means para clusterização com calinskis",
   "id": "41da6161917b3cc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_clusters_silhouette = 2\n",
    "n_clusters_calinskis = 4\n",
    "n_clusters_real = 3\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters_calinskis, random_state=42, n_init=20)\n",
    "labels = kmeans.fit_predict(X_scaled)"
   ],
   "id": "a27f5ffd4ff71c2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"\\nResultados do K-means com k={n_clusters_calinskis}:\")\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"  Cluster {cluster}: {count} frames ({count / len(labels) * 100:.1f}%)\")"
   ],
   "id": "a57f7a4439f99f8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Métricas\n",
    "print(f\"\\nMétricas de qualidade:\")\n",
    "print(f\"  Silhouette Score: {silhouette_score(X_scaled, labels):.3f}\")\n",
    "print(f\"  Calinski-Harabasz: {calinski_harabasz_score(X_scaled, labels):.1f}\")\n",
    "print(f\"  Davies-Bouldin: {davies_bouldin_score(X_scaled, labels):.3f}\")"
   ],
   "id": "5256071abb6ff2c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualizar_clusters_2d(X_scaled, labels, method='pca'):\n",
    "    \"\"\"Visualiza clusters em 2D\"\"\"\n",
    "\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=2)\n",
    "        X_2d = reducer.fit_transform(X_scaled)\n",
    "        var_explained = reducer.explained_variance_ratio_\n",
    "        title = f'Clusters - PCA (Var: {var_explained[0]:.1%} + {var_explained[1]:.1%})'\n",
    "    else:  # tsne\n",
    "        reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "        X_2d = reducer.fit_transform(X_scaled)\n",
    "        title = 'Clusters - t-SNE'\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Plot points\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = labels == label\n",
    "        plt.scatter(X_2d[mask, 0], X_2d[mask, 1],\n",
    "                    c=[colors[i]],\n",
    "                    label=f'Cluster {label}',\n",
    "                    alpha=0.6,\n",
    "                    s=50)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Componente 1')\n",
    "    plt.ylabel('Componente 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "47d7fed2d89defa0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualizar_clusters_2d(X_scaled, labels, 'pca')\n",
   "id": "dee65127a91d3d28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualizar_clusters_2d(X_scaled, labels, 'tsne')",
   "id": "46479ae822fda36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Analise das caracteristicas do cluster",
   "id": "cc540ee4021274f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analisar_caracteristicas_clusters(df, labels, feature_cols):\n",
    "    \"\"\"Analisa características detalhadas de cada cluster\"\"\"\n",
    "\n",
    "    df['cluster'] = labels\n",
    "\n",
    "    # Estatísticas por cluster\n",
    "    cluster_stats = df.groupby('cluster')[feature_cols].agg(['mean', 'std'])\n",
    "\n",
    "    # Para cada cluster, identificar características distintivas\n",
    "    print(\"\\n=== ANÁLISE DETALHADA DOS CLUSTERS ===\")\n",
    "\n",
    "    for cluster in sorted(df['cluster'].unique()):\n",
    "        print(f\"\\n--- CLUSTER {cluster} ---\")\n",
    "        cluster_data = df[df['cluster'] == cluster]\n",
    "        print(f\"Total de frames: {len(cluster_data)} ({len(cluster_data) / len(df) * 100:.1f}%)\")\n",
    "\n",
    "        # Características de cor\n",
    "        print(\"\\nCaracterísticas de Cor:\")\n",
    "        print(f\"  RGB médio: R={cluster_data['mean_r'].mean():.1f}, \"\n",
    "              f\"G={cluster_data['mean_g'].mean():.1f}, \"\n",
    "              f\"B={cluster_data['mean_b'].mean():.1f}\")\n",
    "        print(f\"  Brilho médio: {cluster_data['mean_brightness'].mean():.1f}\")\n",
    "        print(f\"  Saturação média: {cluster_data['saturation'].mean():.3f}\")\n",
    "\n",
    "        # Variabilidade\n",
    "        print(f\"\\nVariabilidade:\")\n",
    "        print(f\"  Desvio padrão de cor (soma): {cluster_data['color_range'].mean():.1f}\")\n",
    "        print(f\"  Frame STD médio: {cluster_data['frame_std'].mean():.1f}\")\n",
    "\n",
    "        # Dominância de cor\n",
    "        print(f\"\\nDominância de Cor:\")\n",
    "        print(f\"  Vermelho: {cluster_data['red_dominance'].mean():.3f}\")\n",
    "        print(f\"  Verde: {cluster_data['green_dominance'].mean():.3f}\")\n",
    "        print(f\"  Azul: {cluster_data['blue_dominance'].mean():.3f}\")\n",
    "\n",
    "        # Frames exemplo\n",
    "        print(f\"\\nFrames exemplo: {cluster_data['frame_number'].head(5).tolist()}\")\n",
    "\n",
    "    # Heatmap das médias\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cluster_means = df.groupby('cluster')[feature_cols].mean()\n",
    "\n",
    "    # Normalizar para visualização\n",
    "    cluster_means_norm = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min())\n",
    "\n",
    "    sns.heatmap(cluster_means_norm.T,\n",
    "                annot=True,\n",
    "                fmt='.2f',\n",
    "                cmap='YlOrRd',\n",
    "                xticklabels=[f'Cluster {i}' for i in cluster_means.index],\n",
    "                yticklabels=feature_cols,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Características Normalizadas por Cluster')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return cluster_stats"
   ],
   "id": "a1696652e2480649",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cluster_stats = analisar_caracteristicas_clusters(df, labels, feature_cols)",
   "id": "db80237723059144",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# cluster 0 é o love_letter\n",
    "# cluster 1 é a caneca\n",
    "# cluster 2 é a banana\n",
    "\n",
    "# cluster 3 é sombra projetada do meu corpo\n"
   ],
   "id": "cbe3d99ecd887689",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_to_object = {\n",
    "    0: 'banana',\n",
    "    1: 'caneca',\n",
    "    2: 'love_letter',\n",
    "    3: 'sombra'  # será ignorado na classificação\n",
    "}\n",
    "\n",
    "# estou adicionando a coluna 'object_real' para demonstrar os labels reais\n",
    "df['object_label'] = df['cluster'].map(cluster_to_object)"
   ],
   "id": "a7982c66a2e0b3ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# removendo os frames de sombra para evitar ter que treinar eles junto e não confundir o modelo\n",
    "df_objects = df[df['object_label'] != 'sombra'].copy()"
   ],
   "id": "208bbb39cdac6516",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df_objects['object_label'].value_counts())",
   "id": "f6d6554759ca68f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Funções auxiliares para extrair features adicionas para alguns frames de exemplo",
   "id": "12a69cd3b169e458"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_texture_features(frame):\n",
    "    \"\"\"Extrai features de textura usando filtros\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) if len(frame.shape) == 3 else frame\n",
    "\n",
    "    # Gradientes de Sobel\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Magnitude do gradiente\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "    # Features de textura\n",
    "    texture_features = {\n",
    "        'gradient_mean': np.mean(gradient_magnitude),\n",
    "        'gradient_std': np.std(gradient_magnitude),\n",
    "        'gradient_max': np.max(gradient_magnitude),\n",
    "        'edge_density': np.sum(gradient_magnitude > np.mean(gradient_magnitude)) / gradient_magnitude.size\n",
    "    }\n",
    "\n",
    "    # Laplacian para detectar bordas\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    texture_features['laplacian_var'] = laplacian.var()\n",
    "\n",
    "    return texture_features"
   ],
   "id": "aa4525584d57e60f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_shape_features(frame):\n",
    "    \"\"\"Extrai features básicas de forma\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) if len(frame.shape) == 3 else frame\n",
    "\n",
    "    # Threshold adaptativo\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    shape_features = {\n",
    "        'num_contours': len(contours),\n",
    "        'total_contour_area': 0,\n",
    "        'max_contour_area': 0,\n",
    "        'contour_density': 0\n",
    "    }\n",
    "\n",
    "    if contours:\n",
    "        areas = [cv2.contourArea(c) for c in contours]\n",
    "        shape_features['total_contour_area'] = sum(areas)\n",
    "        shape_features['max_contour_area'] = max(areas)\n",
    "        shape_features['contour_density'] = shape_features['total_contour_area'] / (gray.shape[0] * gray.shape[1])\n",
    "\n",
    "    return shape_features"
   ],
   "id": "da86b4872f8db93c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extração de frames aleatorios\n",
    "sample_indices = np.random.choice(df_objects.index, size=min(50, len(df_objects)), replace=False)\n",
    "texture_features_list = []\n",
    "shape_features_list = []\n",
    "\n",
    "for idx in sample_indices:\n",
    "    frame_id = df_objects.loc[idx, 'id']\n",
    "    frame = load_frame_from_db(frame_id)\n",
    "\n",
    "    if frame is not None:\n",
    "        texture_feat = extract_texture_features(frame)\n",
    "        shape_feat = extract_shape_features(frame)\n",
    "\n",
    "        texture_features_list.append({**{'id': frame_id}, **texture_feat})\n",
    "        shape_features_list.append({**{'id': frame_id}, **shape_feat})"
   ],
   "id": "53e77db2d7345f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if texture_features_list:\n",
    "    texture_df = pd.DataFrame(texture_features_list)\n",
    "    shape_df = pd.DataFrame(shape_features_list)\n",
    "\n",
    "    # Merge com o dataframe principal\n",
    "    df_enhanced = df_objects.merge(texture_df, on='id', how='left')\n",
    "    df_enhanced = df_enhanced.merge(shape_df, on='id', how='left')\n",
    "\n",
    "    # Preencher NaN com médias\n",
    "    for col in texture_df.columns[1:]:\n",
    "        df_enhanced[col].fillna(df_enhanced[col].mean(), inplace=True)\n",
    "    for col in shape_df.columns[1:]:\n",
    "        df_enhanced[col].fillna(df_enhanced[col].mean(), inplace=True)\n",
    "else:\n",
    "    df_enhanced = df_objects.copy()"
   ],
   "id": "27c60a9cbce893aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Preparação das features para treinar modelo",
   "id": "7037003b7a1b8786"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Features originais\n",
    "feature_cols_ml = [\n",
    "    'mean_r', 'mean_g', 'mean_b',\n",
    "    'std_r', 'std_g', 'std_b',\n",
    "    'brightness_value', 'frame_std',\n",
    "    'color_range', 'mean_brightness', 'color_variance',\n",
    "    'red_dominance', 'green_dominance', 'blue_dominance',\n",
    "    'saturation', 'hue_component'\n",
    "]"
   ],
   "id": "b1a18d8b9738a2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'gradient_mean' in df_enhanced.columns:\n",
    "    feature_cols_ml.extend(['gradient_mean', 'gradient_std', 'laplacian_var', 'edge_density'])\n",
    "if 'num_contours' in df_enhanced.columns:\n",
    "    feature_cols_ml.extend(['num_contours', 'contour_density'])"
   ],
   "id": "aaa4ade033b0f26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "available_features = [col for col in feature_cols_ml if col in df_enhanced.columns]\n",
    "print(f\"\\nFeatures disponíveis para ML: {len(available_features)}\")"
   ],
   "id": "3bebe5ceafba482b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Separação de X (features) e Y (alvo)",
   "id": "9f0d4158610a788f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df_enhanced[available_features].values\n",
    "y = df_enhanced['object_label'].values"
   ],
   "id": "4b18ec0f9badd33c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dividindo X, Y treino e X, Y teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ],
   "id": "2e027f540d49e076",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Normalizar\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "d27b95dd6b59af3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"\\nTamanho do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")"
   ],
   "id": "d8036e01a5e90281",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Random Forest",
   "id": "c076fef49118a1bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== TREINANDO RANDOM FOREST ===\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predições\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "print(\"\\nRelatório de Classificação - Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ],
   "id": "ed553877fb7efedb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SVM (Suport Vector Machine)",
   "id": "8b107404af8b2f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== TREINANDO SVM ===\")\n",
    "svm_model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predições\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "print(\"\\nRelatório de Classificação - SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ],
   "id": "101650951e0501dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Função suporte matrix de confusão",
   "id": "e74718b53e4366f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title, model_name):\n",
    "    \"\"\"Plota matriz de confusão detalhada\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = sorted(np.unique(y_true))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f'Matriz de Confusão - {title}')\n",
    "    plt.ylabel('Classe Real')\n",
    "    plt.xlabel('Classe Predita')\n",
    "\n",
    "    # Adicionar métricas\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    plt.text(0.5, -0.15, f'Acurácia Global: {accuracy:.2%}',\n",
    "             transform=plt.gca().transAxes, ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "b28f7f782d15a005",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Matriz de confusão",
   "id": "8e345807913f032b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Random Forest\n",
    "plot_confusion_matrix(y_test, y_pred_rf, \"Random Forest\", \"RF\")"
   ],
   "id": "3b8ee8a228f7ca47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SVM\n",
    "plot_confusion_matrix(y_test, y_pred_svm, \"SVM\", \"SVM\")"
   ],
   "id": "bae6c332f7fc46da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Análise Importância das features",
   "id": "6106d09f64d4d6ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Importância das features no Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'][:15], feature_importance['importance'][:15])\n",
    "plt.xlabel('Importância')\n",
    "plt.title('Top 15 Features Mais Importantes - Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b40710eaa368df3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nTop 10 features mais importantes:\")\n",
    "print(feature_importance.head(10))"
   ],
   "id": "290a6e1b42a86e1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Detecção de objetos",
   "id": "a137ccec83c4e2a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Funções auxiliar",
   "id": "633fd3d0d05f032f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model = rf_model  # Acabei escolhendo Random Forest por ter tido resultados similares ao SVM\n",
    "model_name = \"Random Forest\"\n",
    "\n",
    "# Selecionar frames de teste (um de cada objeto)\n",
    "test_frames = []\n",
    "for obj in ['love_letter', 'caneca', 'banana']:\n",
    "    obj_frames = df_enhanced[df_enhanced['object_label'] == obj]\n",
    "    if len(obj_frames) > 0:\n",
    "        # Pegar frame do meio do vídeo para cada objeto\n",
    "        mid_idx = len(obj_frames) // 2\n",
    "        test_frames.append(obj_frames.iloc[mid_idx])\n",
    "\n",
    "print(f\"\\nTestando detecção em {len(test_frames)} frames...\")"
   ],
   "id": "5f42c03e0937fdb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_frame_features(frame):\n",
    "    \"\"\"\n",
    "    Extrai features do frame inteiro (como você fazia no clustering)\n",
    "    \"\"\"\n",
    "    # Calcular estatísticas de cor\n",
    "    if len(frame.shape) == 3:\n",
    "        b, g, r = cv2.split(frame)\n",
    "        stats = {\n",
    "            'mean_r': float(np.mean(r)),\n",
    "            'mean_g': float(np.mean(g)),\n",
    "            'mean_b': float(np.mean(b)),\n",
    "            'std_r': float(np.std(r)),\n",
    "            'std_g': float(np.std(g)),\n",
    "            'std_b': float(np.std(b))\n",
    "        }\n",
    "    else:\n",
    "        mean_val = float(np.mean(frame))\n",
    "        std_val = float(np.std(frame))\n",
    "        stats = {\n",
    "            'mean_r': mean_val, 'mean_g': mean_val, 'mean_b': mean_val,\n",
    "            'std_r': std_val, 'std_g': std_val, 'std_b': std_val\n",
    "        }\n",
    "\n",
    "    # Brilho e outras features\n",
    "    brightness = np.mean(frame)\n",
    "    frame_std = np.std(frame)\n",
    "\n",
    "    # Features derivadas (igual ao seu código original)\n",
    "    color_range = stats['std_r'] + stats['std_g'] + stats['std_b']\n",
    "    mean_brightness = (stats['mean_r'] + stats['mean_g'] + stats['mean_b']) / 3\n",
    "    color_variance = (stats['std_r'] ** 2 + stats['std_g'] ** 2 + stats['std_b'] ** 2) / 3\n",
    "\n",
    "    total = stats['mean_r'] + stats['mean_g'] + stats['mean_b'] + 1e-6\n",
    "    red_dominance = stats['mean_r'] / total\n",
    "    green_dominance = stats['mean_g'] / total\n",
    "    blue_dominance = stats['mean_b'] / total\n",
    "\n",
    "    max_rgb = max(stats['mean_r'], stats['mean_g'], stats['mean_b'])\n",
    "    min_rgb = min(stats['mean_r'], stats['mean_g'], stats['mean_b'])\n",
    "    chroma = max_rgb - min_rgb\n",
    "    saturation = chroma / max_rgb if max_rgb > 0 else 0\n",
    "\n",
    "    if chroma > 0:\n",
    "        if max_rgb == stats['mean_r']:\n",
    "            hue_component = (stats['mean_g'] - stats['mean_b']) / chroma\n",
    "        elif max_rgb == stats['mean_g']:\n",
    "            hue_component = 2 + (stats['mean_b'] - stats['mean_r']) / chroma\n",
    "        else:\n",
    "            hue_component = 4 + (stats['mean_r'] - stats['mean_g']) / chroma\n",
    "    else:\n",
    "        hue_component = 0\n",
    "\n",
    "    features = [\n",
    "        stats['mean_r'], stats['mean_g'], stats['mean_b'],\n",
    "        stats['std_r'], stats['std_g'], stats['std_b'],\n",
    "        brightness, frame_std,\n",
    "        color_range, mean_brightness, color_variance,\n",
    "        red_dominance, green_dominance, blue_dominance,\n",
    "        saturation, hue_component\n",
    "    ]\n",
    "\n",
    "    return features"
   ],
   "id": "8f48e27e53dad017",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_detections(obj, frame, detections, title=\"Detecção de Objetos\", output_path=None, show_plot=True):\n",
    "    \"\"\"\n",
    "    Visualiza frame com bounding boxes e labels\n",
    "\n",
    "    Args:\n",
    "        frame: imagem em formato BGR (OpenCV)\n",
    "        detections: lista de detecções\n",
    "        title: título para visualização\n",
    "        output_path: caminho para salvar a imagem (opcional)\n",
    "        show_plot: se deve mostrar o plot com matplotlib\n",
    "    \"\"\"\n",
    "    frame_vis = frame.copy()\n",
    "\n",
    "    # Cores para cada classe\n",
    "    colors = {\n",
    "        'love_letter': (0, 0, 255),  # Vermelho\n",
    "        'caneca': (255, 255, 255),  # Branco em BGR\n",
    "        'banana': (0, 255, 255),  # Amarelo em BGR\n",
    "        'sombra': (128, 128, 128)  # Cinza\n",
    "    }\n",
    "\n",
    "    # Desenhar todas as detecções\n",
    "    for det in detections:\n",
    "        x, y, w, h = det['bbox']\n",
    "        label = det['label']\n",
    "        confidence = det['confidence']\n",
    "\n",
    "        # Desenhar bounding box\n",
    "        color = colors.get(label, (255, 255, 255))\n",
    "        cv2.rectangle(frame_vis, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "        # Adicionar label\n",
    "        text = f\"{label} ({confidence:.2f})\"\n",
    "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "\n",
    "        # Background para texto\n",
    "        cv2.rectangle(frame_vis, (x, y - 25), (x + text_size[0], y), color, -1)\n",
    "\n",
    "        # Texto\n",
    "        cv2.putText(frame_vis, text, (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    # Salvar imagem se path fornecido\n",
    "    if output_path is not None:\n",
    "        try:\n",
    "            # Criar diretório se não existir\n",
    "            output_dir = os.path.dirname(f\"{output_path}/{obj}\")\n",
    "            if output_dir and not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                print(f\"Diretório criado: {output_dir}\")\n",
    "\n",
    "            # Verificar se o frame está no formato correto\n",
    "            if frame_vis.dtype != np.uint8:\n",
    "                print(f\"Aviso: Convertendo tipo de dados de {frame_vis.dtype} para uint8\")\n",
    "                frame_vis = frame_vis.astype(np.uint8)\n",
    "\n",
    "            # Salvar imagem\n",
    "            success = cv2.imwrite(output_path, frame_vis)\n",
    "\n",
    "            if success:\n",
    "                print(f\"✓ Imagem salva com sucesso: {output_path}\")\n",
    "                # Verificar se o arquivo foi realmente criado\n",
    "                if os.path.exists(output_path):\n",
    "                    file_size = os.path.getsize(output_path)\n",
    "                    print(f\"  Tamanho do arquivo: {file_size} bytes\")\n",
    "                else:\n",
    "                    print(\"  AVISO: cv2.imwrite retornou True mas arquivo não encontrado!\")\n",
    "            else:\n",
    "                print(f\"✗ Erro ao salvar imagem: {output_path}\")\n",
    "                print(f\"  Verifique se o formato é suportado (.jpg, .png, .bmp)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Exceção ao salvar imagem: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # Mostrar plot se solicitado\n",
    "    if show_plot:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        # Converter BGR para RGB para matplotlib\n",
    "        plt.imshow(cv2.cvtColor(frame_vis, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return frame_vis\n"
   ],
   "id": "a0d004e032c9da8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_largest_object_bbox(frame, min_area_ratio=0.01, max_area_ratio=0.9):\n",
    "    \"\"\"\n",
    "    Função para encontrar objetos\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    total_area = height * width\n",
    "\n",
    "    print(f\"Frame shape: {height}x{width}, total_area: {total_area}\")\n",
    "\n",
    "    # Converter para escala de cinza\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) if len(frame.shape) == 3 else frame\n",
    "    print(f\"Gray shape: {gray.shape}\")\n",
    "\n",
    "    # Blur para reduzir ruído\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # TESTAR DIFERENTES TIPOS DE THRESHOLD\n",
    "    print(\"\\n=== TESTANDO DIFERENTES THRESHOLDS ===\")\n",
    "\n",
    "    # 1. Threshold adaptativo\n",
    "    thresh_adaptive = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV, 21, 10\n",
    "    )\n",
    "\n",
    "    # 2. Threshold simples (Otsu)\n",
    "    _, thresh_otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 3. Threshold manual\n",
    "    _, thresh_manual = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Testar cada threshold\n",
    "    thresholds = {\n",
    "        'adaptive': thresh_adaptive,\n",
    "        'otsu': thresh_otsu,\n",
    "        'manual': thresh_manual\n",
    "    }\n",
    "\n",
    "    best_result = None\n",
    "    best_contour_count = 0\n",
    "\n",
    "    for thresh_name, thresh in thresholds.items():\n",
    "        print(f\"\\n--- Testando {thresh_name} ---\")\n",
    "\n",
    "        # Operações morfológicas\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Encontrar contornos\n",
    "        contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        print(f\"Contornos encontrados: {len(contours)}\")\n",
    "\n",
    "        if not contours:\n",
    "            continue\n",
    "\n",
    "        # Analisar contornos\n",
    "        valid_contours = []\n",
    "        for i, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            area_ratio = area / total_area\n",
    "\n",
    "            print(f\"  Contorno {i}: área={area}, ratio={area_ratio:.4f}\")\n",
    "\n",
    "            if min_area_ratio <= area_ratio <= max_area_ratio:\n",
    "                valid_contours.append((contour, area))\n",
    "                print(f\"    ✓ VÁLIDO!\")\n",
    "            else:\n",
    "                print(f\"    ✗ Rejeitado (fora do range {min_area_ratio}-{max_area_ratio})\")\n",
    "\n",
    "        print(f\"Contornos válidos: {len(valid_contours)}\")\n",
    "\n",
    "        if valid_contours and len(valid_contours) > best_contour_count:\n",
    "            best_contour_count = len(valid_contours)\n",
    "            largest_contour = max(valid_contours, key=lambda x: x[1])[0]\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "            best_result = {\n",
    "                'bbox': (x, y, w, h),\n",
    "                'method': thresh_name,\n",
    "                'contour': largest_contour,\n",
    "                'thresh_image': cleaned\n",
    "            }\n",
    "\n",
    "            print(f\"    → Melhor resultado até agora: bbox=({x}, {y}, {w}, {h})\")\n",
    "\n",
    "    return best_result\n"
   ],
   "id": "77ebefc1304a7cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def classify_and_detect_single_object(frame, model, scaler, available_features):\n",
    "    \"\"\"\n",
    "    Função de classificar e detectar objetos\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. CLASSIFICAR O FRAME INTEIRO\n",
    "    frame_features = extract_frame_features(frame)\n",
    "\n",
    "    # Ajustar features para o modelo\n",
    "    if len(frame_features) < len(available_features):\n",
    "        frame_features.extend([0] * (len(available_features) - len(frame_features)))\n",
    "    frame_features = frame_features[:len(available_features)]\n",
    "\n",
    "\n",
    "    # Verificar se há NaN ou inf\n",
    "    if any(np.isnan(frame_features)) or any(np.isinf(frame_features)):\n",
    "        print(\"AVISO: Features inválidas detectadas!\")\n",
    "        return []\n",
    "\n",
    "    # Predizer classe do frame\n",
    "    frame_features_scaled = scaler.transform([frame_features])\n",
    "    predicted_class = model.predict(frame_features_scaled)[0]\n",
    "\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        proba = model.predict_proba(frame_features_scaled)[0]\n",
    "        confidence = max(proba)\n",
    "        print(f\"Probabilidades: {dict(zip(model.classes_, proba))}\")\n",
    "    else:\n",
    "        confidence = 1.0\n",
    "\n",
    "    print(f\"Frame classificado como: {predicted_class} (confiança: {confidence:.2f})\")\n",
    "\n",
    "    result = find_largest_object_bbox(frame)\n",
    "\n",
    "    if result is None:\n",
    "        print(\"Nenhum objeto encontrado!\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Objeto encontrado! Método: {result['method']}, BBox: {result['bbox']}\")\n",
    "\n",
    "    return [{\n",
    "        'bbox': result['bbox'],\n",
    "        'label': predicted_class,\n",
    "        'confidence': confidence,\n",
    "        'area': result['bbox'][2] * result['bbox'][3],  # w * h\n",
    "        'detection_method': result['method']\n",
    "    }]\n"
   ],
   "id": "d88b3bd80eb60e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detect_single_frame(frame_id, obj):\n",
    "    \"\"\"\n",
    "    Detecção para unico frame por vez\n",
    "    \"\"\"\n",
    "    frame = load_frame_from_db(frame_id)\n",
    "    if frame is None:\n",
    "        print(\"Frame não encontrado!\")\n",
    "        return\n",
    "\n",
    "    detections = classify_and_detect_single_object(frame, best_model, scaler, available_features)\n",
    "\n",
    "    # Salvar frame original para inspeção\n",
    "    cv2.imwrite(f\"data/bounding_box_images/{obj}/{frame_id}_original.jpg\", frame)\n",
    "    print(f\"Frame original salvo: data/bounding_box_images/{obj}/{frame_id}_original.jpg\")\n",
    "\n",
    "    if detections:\n",
    "        print(\"\\nDETECÇÃO BEM-SUCEDIDA!\")\n",
    "        for i, det in enumerate(detections):\n",
    "            print(f\"Detecção {i+1}:\")\n",
    "            print(f\"  Label: {det['label']}\")\n",
    "            print(f\"  Confiança: {det['confidence']:.2f}\")\n",
    "            print(f\"  BBox: {det['bbox']}\")\n",
    "            print(f\"  Método: {det.get('detection_method', 'N/A')}\")\n",
    "\n",
    "        # Visualizar resultado\n",
    "        vis_frame = visualize_detections(obj, frame, detections, f\"Debug Frame {frame_id}\", show_plot=False)\n",
    "        cv2.imwrite(f\"data/bounding_box_images/{obj}/{frame_id}_detected.jpg\", vis_frame)\n",
    "        print(f\"Resultado salvo: data/bounding_box_images/{obj}/{frame_id}_detected.jpg\")\n",
    "    else:\n",
    "        print(\"\\nNENHUMA DETECÇÃO!\")\n",
    "\n",
    "    return detections"
   ],
   "id": "5288802d86cf2f36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pegar um frame de cada classe para testar\n",
    "test_frames_debug = []\n",
    "for obj in ['banana', 'love_letter', 'caneca']:\n",
    "    obj_frames = df_enhanced[df_enhanced['object_label'] == obj]\n",
    "    if len(obj_frames) > 0:\n",
    "        for i in range(min(10, len(obj_frames))):\n",
    "            frame_info = obj_frames.iloc[i]\n",
    "            print(f\"\\nTestando {obj} - Frame ID: {frame_info['id']}\")\n",
    "            detections = detect_single_frame(int(frame_info['id']), obj)\n",
    "            test_frames_debug.append((obj, frame_info, detections))\n",
    "\n",
    "print(f\"\\n=== RESUMO DA EXECUÇÃO ===\")\n",
    "for obj, frame_info, detections in test_frames_debug:\n",
    "    status = \"OK\" if detections else \"FALHOU\"\n",
    "    print(f\"{obj}: {status}\")"
   ],
   "id": "ac3b0acc0d96efcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "incorrect_predictions = X_test_scaled[y_test != y_pred_rf]\n",
    "incorrect_true = y_test[y_test != y_pred_rf]\n",
    "incorrect_pred = y_pred_rf[y_test != y_pred_rf]"
   ],
   "id": "bea1f0e7202ba8b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if len(incorrect_predictions) > 0:\n",
    "    print(f\"\\nTotal de erros: {len(incorrect_predictions)} ({len(incorrect_predictions) / len(y_test) * 100:.1f}%)\")\n",
    "\n",
    "    # Analisar padrões de erro\n",
    "    error_patterns = pd.DataFrame({\n",
    "        'true_label': incorrect_true,\n",
    "        'predicted_label': incorrect_pred\n",
    "    })\n",
    "\n",
    "    print(\"\\nPadrões de erro mais comuns:\")\n",
    "    print(error_patterns.groupby(['true_label', 'predicted_label']).size().sort_values(ascending=False))\n",
    "\n",
    "    # Análise de features dos erros\n",
    "    print(\"\\n\\nAnálise de features médias por tipo de erro:\")\n",
    "    for true_label in np.unique(incorrect_true):\n",
    "        mask = incorrect_true == true_label\n",
    "        if np.sum(mask) > 0:\n",
    "            print(f\"\\n{true_label} classificado incorretamente:\")\n",
    "            error_features = incorrect_predictions[mask].mean(axis=0)\n",
    "\n",
    "            # Comparar com features médias corretas\n",
    "            correct_mask = (y_train == true_label)\n",
    "            if np.sum(correct_mask) > 0:\n",
    "                correct_features = X_train_scaled[correct_mask].mean(axis=0)\n",
    "\n",
    "                # Maiores diferenças\n",
    "                diff = np.abs(error_features - correct_features)\n",
    "                top_diff_idx = np.argsort(diff)[-5:][::-1]\n",
    "\n",
    "                print(\"  Features com maior diferença:\")\n",
    "                for idx in top_diff_idx:\n",
    "                    print(f\"    {available_features[idx]}: {diff[idx]:.3f}\")"
   ],
   "id": "ae9eaa4b8dbb741b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== CONCLUSÃO ===\")\n",
    "print(f\"Melhor modelo: {model_name}\")\n",
    "print(f\"Acurácia no teste: {np.mean(y_test == y_pred_rf):.2%}\")\n",
    "print(\"\\nO modelo está pronto para classificar os objetos no vídeo!\")"
   ],
   "id": "177404c6ad32c34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "# Salvar o melhor modelo e o scaler\n",
    "joblib.dump(best_model, 'models/best_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "print(\"\\nModelo e scaler salvos em 'best_model.pkl' e 'scaler.pkl'\")"
   ],
   "id": "e918eeb6a2398930",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transcrição de Aúdio",
   "id": "b9dff936e4130ac2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "\n",
    "# Obtém o caminho absoluto da pasta 'ffmpeg' no seu projeto\n",
    "project_root = Path.cwd()  # Pasta onde o Jupyter está executando\n",
    "ffmpeg_path = project_root / \"ffmpeg\"\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + str(ffmpeg_path)"
   ],
   "id": "61f43e688fcf779a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Comando especifico para macOS\n",
    "#\n",
    "# ! xattr -d com.apple.quarantine ffmpeg/ffmpeg\n",
    "# ! xattr -d com.apple.quarantine ffmpeg/ffprobe\n",
    "\n",
    "# OU USAR ESTE:\n",
    "# ! chmod +x ffmpeg/ffmpeg\n",
    "# ! chmod +x ffmpeg/ffprobe"
   ],
   "id": "e7fab0a1132dc6a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Caminho do arquivo MP3\n",
    "audio_mp3 = \"data/audio.mp3\"\n",
    "\n",
    "# Converte MP3 para WAV\n",
    "audio = AudioSegment.from_mp3(audio_mp3)"
   ],
   "id": "4c41fd19e4dd7a92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio_wav = \"temp_audio.wav\"\n",
    "audio.export(audio_wav, format=\"wav\")"
   ],
   "id": "b4166ff9f978f60f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inicializa o reconhecedor\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Lê o arquivo de áudio\n",
    "with sr.AudioFile(audio_wav) as source:\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "# Transcreve o áudio para texto\n",
    "try:\n",
    "    texto = r.recognize_google(audio_data, language=\"pt-BR\")\n",
    "    print(\"Texto transcrito:\")\n",
    "    print(texto)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Não foi possível entender o áudio.\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Erro ao se conectar ao serviço de reconhecimento: {e}\")"
   ],
   "id": "2c82b16d3cb2e18f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Salva em um arquivo .txt\n",
    "with open(\"data/transcricao_audio/transcricao.txt\", \"w\", encoding=\"utf-8\") as arquivo:\n",
    "    arquivo.write(texto)"
   ],
   "id": "5b9e96679869abc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if os.path.exists(\"temp_audio.wav\"):\n",
    "    os.remove(\"temp_audio.wav\")\n",
    "    print(\"Arquivo 'temp_audio.wav' deletado com sucesso!\")\n",
    "else:\n",
    "    print(\"Arquivo 'temp_audio.wav' não encontrado.\")"
   ],
   "id": "f085d0a200595253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip freeze",
   "id": "922410782ca62ab0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ad5cbe25b6848934",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
